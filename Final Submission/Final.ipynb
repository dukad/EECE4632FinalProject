{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659a2406",
   "metadata": {},
   "source": [
    "## Audio Equalizer Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68161a0e",
   "metadata": {},
   "source": [
    "### Filter Class Code\n",
    "Describes filter-type object, which contains filter coefficients for low, mid, or high frequency filter, or no coefficients for unspecified filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import kaiserord, firwin, freqz\n",
    "from pylab import figure, plot, title, grid, xlabel, ylabel\n",
    "import numpy as np\n",
    "\n",
    "class Filter:\n",
    "    def __init__(self, filter_type='none', num_coefs=99, nyquist_rate=22050, stop_band_attentuation_dB=60, low_transition_freq=400, high_transition_freq=4000):\n",
    "        \"\"\"\n",
    "        __init__ Initializes filter parameters based on passed values\n",
    "\n",
    "        Args:\n",
    "            filter_type (str, optional): 'Low', 'mid', or 'high' to specify what type of filter to generate\n",
    "                    Defaults to 'empty', indicating that no coefs should be generated\n",
    "            num_coefs (int, optional): Number of filter coefficients to generate\n",
    "                    Defaults to 99, keep this unless HLS code is changed as well\n",
    "            nyquist_rate (int, optional): Nyquist rate of signal to filter\n",
    "                    Defaults to 22050 for the sample audio file \"elecric_guitar_sample.wav\"\n",
    "                    #TODO: Implement dynamic nyquist rate (out of scope for now)\n",
    "            stop_band_attentuation_dB (int, optional): Attenuation frequency for filters\n",
    "                    Defaults to 60dB\n",
    "            low_transition_freq (int, optional): Frequency defining the intersection point of the low and mid frequency bands\n",
    "                    Defaults to 400Hz\n",
    "            high_transition_freq (int, optional): Frequency defining the intersection point of the mid and high frequency bands\n",
    "                    Defaults to 4000Hz\n",
    "        \"\"\"\n",
    "        self.filter_type = filter_type\n",
    "        self.num_coefs = num_coefs\n",
    "        self.nyquist_rate = nyquist_rate\n",
    "        self.transition_width = 200 / nyquist_rate\n",
    "        self.stop_band_attenuation_dB = stop_band_attentuation_dB\n",
    "        self.low_transition_freq = low_transition_freq\n",
    "        self.high_transition_freq = high_transition_freq\n",
    "        \n",
    "        self.filter_coefs = []\n",
    "        \n",
    "        self.calculate_filter_order()\n",
    "        self.generate_filter_coefs()\n",
    "    \n",
    "    \n",
    "    def calculate_filter_order(self):\n",
    "        \"\"\"\n",
    "        calculate_filter_order Calculates filter order based on transition width and attenuation\n",
    "        \"\"\"\n",
    "        # Calculates filter order and beta value based on transition width and attenuation\n",
    "        self.FIR_order, self.beta = kaiserord(self.stop_band_attenuation_dB, self.transition_width)\n",
    "        \n",
    "        # Scaled by 3 to improve accuracy, this will be used as the number of coefficients to generate\n",
    "        self.FIR_order *= 3\n",
    "        \n",
    "        # Some limitations around filters with an even number of coefficients, so make it odd to avoid this altogether\n",
    "        if self.FIR_order % 2 == 0:\n",
    "            self.FIR_order += 1\n",
    "    \n",
    "    \n",
    "    def generate_filter_coefs(self):\n",
    "        \"\"\"\n",
    "        generate_filter_coefs Calls filter generation function based on filter type\n",
    "        \"\"\"\n",
    "        if self.filter_type == \"low\":\n",
    "            self.generate_lowfreq_filter()\n",
    "        elif self.filter_type == \"mid\":\n",
    "            self.generate_midfreq_filter()\n",
    "        elif self.filter_type == \"high\":\n",
    "            self.generate_highfreq_filter()\n",
    "        elif self.filter_type == 'none':\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    def generate_lowfreq_filter(self):\n",
    "        \"\"\"\n",
    "        generate_lowfreq_filter Generates filter coefficients for a lowpass filter with given parameters\n",
    "        \"\"\"\n",
    "        self.filter_coefs = firwin(self.num_coefs, self.low_transition_freq, pass_zero='lowpass', fs=self.nyquist_rate*2)\n",
    "\n",
    "    \n",
    "    def generate_midfreq_filter(self):\n",
    "        \"\"\"\n",
    "        generate_midfreq_filter Generates filter coefficients for a bandstop filter with given parameters\n",
    "        \"\"\"\n",
    "        self.filter_coefs = firwin(self.num_coefs, [self.low_transition_freq / self.nyquist_rate, self.high_transition_freq / self.nyquist_rate], pass_zero='bandpass')\n",
    "\n",
    "    \n",
    "    def generate_highfreq_filter(self):\n",
    "        \"\"\"\n",
    "        generate_highfreq_filter Generates filter coefficients for a highpass filter with given parameters\n",
    "        \"\"\"\n",
    "        self.filter_coefs = firwin(self.num_coefs, self.high_transition_freq, pass_zero='highpass', fs=self.nyquist_rate*2)\n",
    "\n",
    "    \n",
    "    def plot_filter(self):\n",
    "        \"\"\"\n",
    "        plot_filter Plots the frequency response of the filter\n",
    "        \"\"\"        \n",
    "        figure()\n",
    "\n",
    "        # Computes the frequecy response of the filter\n",
    "        response_frequencies, complex_response = freqz(self.filter_coefs, worN=8000)\n",
    "        \n",
    "        plot((response_frequencies / np.pi) * self.nyquist_rate, np.absolute(complex_response), linewidth=2)\n",
    "        \n",
    "        title(\"Filter Curves\")\n",
    "        xlabel(\"Frequency (Hz)\")\n",
    "        ylabel(\"Filter Gain\")\n",
    "        \n",
    "        grid(True)\n",
    "        \n",
    "\n",
    "print(\"Created Filter Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c515e285",
   "metadata": {},
   "source": [
    "#### Filter Test Code\n",
    "Generates low, mid, and high frequency filters, then combined and scaled coefficients into a single filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowfreq_filter = Filter('low')\n",
    "midfreq_filter = Filter('mid')\n",
    "highfreq_filter = Filter('high')\n",
    "\n",
    "# lowfreq_filter.plot_filter()\n",
    "# midfreq_filter.plot_filter()\n",
    "# highfreq_filter.plot_filter()\n",
    "\n",
    "new_filter = Filter()\n",
    "new_filter.filter_coefs = lowfreq_filter.filter_coefs * 0.6 + midfreq_filter.filter_coefs * 0.3 + highfreq_filter.filter_coefs * 0.4\n",
    "new_filter.plot_filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7961f",
   "metadata": {},
   "source": [
    "### Audio Signal Class Code\n",
    "Describes audio_signal-type objects, which contains various methods for reading/writing audio signal to/from wav files, and methods for equalizing the signal either in software or hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738bb50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "from pynq import Overlay\n",
    "from pynq import allocate\n",
    "\n",
    "class Audio_Signal:\n",
    "    def __init__(self, input_file_path, output_file_path):\n",
    "        \"\"\"\n",
    "        __init__ Initializes input and output filepaths based on passed parameters\n",
    "\n",
    "        Args:\n",
    "            input_file_path (string): Input wav file\n",
    "            output_file_path (string): Output wav file\n",
    "        \"\"\"\n",
    "        self.input_file_path = input_file_path\n",
    "        self.output_file_path = output_file_path\n",
    "        \n",
    "        self.sw_output_file_path = './outputs/SW_equalized_output.wav'\n",
    "        self.hw_output_file_path = './outputs/HW_equalized_output.wav'\n",
    "\n",
    "    \n",
    "    def load_audio(self):\n",
    "        \"\"\"\n",
    "        load_audio Reads audio data from input wav file and extracts signal parameters\n",
    "        \"\"\"\n",
    "        audio_signal = wave.open(self.input_file_path, 'r')\n",
    "        \n",
    "        # Pull signal parameters from header\n",
    "        self.frame_count = audio_signal.getnframes()\n",
    "        self.channel_count = audio_signal.getnchannels()\n",
    "        self.sample_width = audio_signal.getsampwidth()\n",
    "        self.sample_rate = audio_signal.getframerate()\n",
    "        self.frame_rate = audio_signal.getframerate() * 2\n",
    "\n",
    "        # Load audio frames from wav file and convert to numpy array\n",
    "        self.audio_frames = audio_signal.readframes(self.frame_count)\n",
    "        self.audio_frames = np.frombuffer(self.audio_frames, dtype = np.int16)\n",
    "        \n",
    "        # Determine length of audio signal (Should be 2 * frame_cound)\n",
    "        self.audio_length = len(self.audio_frames)\n",
    "    \n",
    "    \n",
    "    def plot_audio_data(self):\n",
    "        \"\"\"\n",
    "        plot_audio_data Plots amplitude vs. time of audio signal\n",
    "        \"\"\"\n",
    "        # Generate time signal based on audio data and frame rate\n",
    "        self.time_signal = np.linspace(0, self.audio_length / self.frame_rate, num = self.audio_length)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.time_signal, self.audio_frames)\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Signal Amplitude\")\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    ###   SOFTWARE EQUALIZATION FUNCTIONS   ###\n",
    "    def SW_equalize(self, lowfreq_gain, midfreq_gain, highfreq_gain):\n",
    "        \"\"\"\n",
    "        SW_equalize Equalizes the audio signal, scaling by respective gain for low, mid, and high frequencies\n",
    "\n",
    "        Args:\n",
    "            lowfreq_gain (float): Specifies gain of low frequency components of audio signal\n",
    "                    Must be positive for proper equalization\n",
    "            midfreq_gain (float): Specifies gain of mid frequency components of audio signal\n",
    "                    Must be positive for proper equalization\n",
    "            highfreq_gain (float): Specifies gain of high frequency components of audio signal\n",
    "                    Must be positive for proper equalization\n",
    "        \"\"\"\n",
    "        self.num_coefs = 99\n",
    "\n",
    "        # Generate, combine, and scale filter coefficients for software function\n",
    "        self.make_sw_coefs(lowfreq_gain, midfreq_gain, highfreq_gain)\n",
    "\n",
    "        # Filter audio data using generated filter coefficients\n",
    "        self.sw_equalized_signal = lfilter(self.coefs.filter_coefs, 1.0, self.audio_frames)\n",
    "        \n",
    "        # Do we want to call this now or have the use manually call it?\n",
    "        # Is this the best way to transfer the audio signal between the two parts of the project?\n",
    "        # Or should we just transfer using numpy arrays?\n",
    "        self.write_to_wav_file(self.sw_equalized_signal, self.sw_output_file_path)\n",
    "\n",
    "    \n",
    "    def make_sw_coefs(self, lowfreq_gain, midfreq_gain, highfreq_gain):\n",
    "        \"\"\"\n",
    "        make_sw_coefs Generates and scales filter coefficients for software equalizer\n",
    "\n",
    "        Args:\n",
    "            lowfreq_gain (float): Specifies gain of low frequency components of audio signal\n",
    "                    Must be positive for proper equalization\n",
    "            midfreq_gain (float): Specifies gain of mid frequency components of audio signal\n",
    "                    Must be positive for proper equalization\n",
    "            highfreq_gain (float): Specifies gain of high frequency components of audio signal\n",
    "                    Must be positive for proper equalization\n",
    "        \"\"\"\n",
    "        self.lowfreq_filter = Filter('low')\n",
    "        self.midfreq_filter = Filter('mid')\n",
    "        self.highfreq_filter = Filter('high')\n",
    "        \n",
    "        # Combine filter coefficients into single filter based on gain for each band\n",
    "        self.coefs = Filter()\n",
    "        self.coefs.filter_coefs = (self.lowfreq_filter.filter_coefs * lowfreq_gain\n",
    "                                   + self.midfreq_filter.filter_coefs * midfreq_gain\n",
    "                                   + self.highfreq_filter.filter_coefs * highfreq_gain)\n",
    "\n",
    "    \n",
    "    ###   HARDWARE EQUALIZATION FUNCTIONS   ###\n",
    "    def equalize(self, lowfreq_gain, midfreq_gain, highfreq_gain):\n",
    "        \"\"\"\n",
    "        equalize Equalizes the audio signal using hardware overlay, scaling by respective gain for low, mid, and high frequencies\n",
    "\n",
    "        Args:\n",
    "            lowfreq_gain (float): Specifies gain of low frequency components of audio signal\n",
    "                    Must be positive for proper equalization\n",
    "            midfreq_gain (float): Specifies gain of mid frequency components of audio signal\n",
    "                    Must be positive for proper equalization\n",
    "            highfreq_gain (float): Specifies gain of high frequency components of audio signal\n",
    "                    Must be positive for proper equalization\n",
    "        \"\"\"\n",
    "        self.num_codes = 2\n",
    "        self.num_bands = 3\n",
    "        self.num_coefs = 99\n",
    "        \n",
    "        # Buffer = START + (gain + coefs for each band of equalizer) + STOP + signal values\n",
    "        self.buffer_length = self.num_codes + self.num_bands * (1 + self.num_coefs) + self.audio_length\n",
    "        # Test bufer = START + (gain + coefs for each band of equalizer) + STOP + signal values\n",
    "        # self.buffer_length = self.num_codes + self.num_bands * (1 + self.num_coefs) + 99\n",
    "        self.buffer_header_length = self.num_codes + self.num_bands * (1 + self.num_coefs)\n",
    "        \n",
    "        # Load overlay\n",
    "        overlay = Overlay('/home/xilinx/pynq/overlays/equalizer_with_coefs/equalizer_with_coefs.bit')\n",
    "        #overlay?\n",
    "\n",
    "        # Set auto-reset bit to 0\n",
    "        hls_ip = overlay.axi_dma_0\n",
    "        CONTROL_REGISTER = 0x0\n",
    "        hls_ip.write(CONTROL_REGISTER, 0x01)\n",
    "        overlay.axi_dma_0.register_map\n",
    "        \n",
    "        # Label DMA for data transfers and initialize input/output buffers\n",
    "        dma = overlay.axi_dma_0     \n",
    "        self.input_buffer = allocate(shape=(self.buffer_length,), dtype=np.int32)\n",
    "        self.output_buffer = allocate(shape=(self.buffer_length,), dtype=np.int32)\n",
    "        \n",
    "        # Arbitrarily chosen scale factor used to scale coefficients and de-scale signal after equalization\n",
    "        # Workaround for dealing with issues with float implementation\n",
    "        self.scale_factor = 100000\n",
    "        \n",
    "        # Generate filter coefficients for low, mid, and high frequency filters\n",
    "        self.make_coefs()\n",
    "\n",
    "        # Format start/stop coefs, filter gains and coefficients, and audio signal for sending to hardware overlay\n",
    "        self.format_input(lowfreq_gain, midfreq_gain, highfreq_gain)\n",
    "\n",
    "        # Send and receive data from hardware overlay\n",
    "        print(\"Running filter function\")\n",
    "        self.run_filter(dma)\n",
    "\n",
    "        # Write equalized signal to output wav file\n",
    "        self.hw_equalized_signal = self.output_buffer / self.scale_factor\n",
    "        self.write_to_wav_file(self.hw_equalized_signal, self.hw_output_file_path)\n",
    "    \n",
    "    \n",
    "    def make_coefs(self):\n",
    "        \"\"\"\n",
    "        make_coefs Generates 1-D array of filter coefficients for hardware overlay equalizer\n",
    "                Contains coefficients for low, mid, and high frequency filters, in that order\n",
    "        \"\"\"\n",
    "        self.lowfreq_filter = Filter('low')\n",
    "        self.midfreq_filter = Filter('mid')\n",
    "        self.highfreq_filter = Filter('high')\n",
    "        \n",
    "\n",
    "        self.coefs = [0] * (self.num_bands * self.num_coefs)\n",
    "        \n",
    "        # Potential replacement for above for loops:\n",
    "        for i in range(self.num_coefs):\n",
    "            self.coefs[i] = self.lowfreq_filter.filter_coefs[i]\n",
    "            self.coefs[i + self.num_coefs] = self.midfreq_filter.filter_coefs[i]\n",
    "            self.coefs[i + 2 * self.num_coefs] = self.highfreq_filter.filter_coefs[i]\n",
    "        \n",
    "        print(\"Coefs generated\")\n",
    "    \n",
    "    \n",
    "    def format_input(self, lowfreq_gain, midfreq_gain, highfreq_gain):\n",
    "        \"\"\"\n",
    "        format_input Formats input_buffer for sending to hardware overlay\n",
    "                Format is as follows:\n",
    "                    1. Start code (0xBEEF)\n",
    "                    2. Gain for low frequency components of audio signal\n",
    "                    3. Low frequency filter coefficients\n",
    "                    4. Gain for mid frequency components of audio signal\n",
    "                    5. Mid frequency filter coefficients\n",
    "                    6. Gain for high frequency components of audio signal\n",
    "                    7. High frequency filter coefficients\n",
    "                    8. Stop code (0xABBA)\n",
    "                    9. Audio signal\n",
    "\n",
    "        Args:\n",
    "            lowfreq_gain (float): Specifies gain of low frequency components of audio signal\n",
    "                    Must be positive for proper equalization\n",
    "            midfreq_gain (float): Specifies gain of mid frequency components of audio signal\n",
    "                    Must be positive for proper equalization\n",
    "            highfreq_gain (float): Specifies gain of high frequency components of audio signal\n",
    "                    Must be positive for proper equalization\n",
    "        \"\"\"\n",
    "        offset = 0\n",
    "\n",
    "        self.input_buffer[offset] = 0xBEEF\n",
    "        offset += 1\n",
    "        \n",
    "        self.input_buffer[offset] = lowfreq_gain\n",
    "        offset += 1\n",
    "\n",
    "        for coef in range(self.num_coefs):\n",
    "            self.input_buffer[coef + offset] = self.coefs[coef] * self.scale_factor\n",
    "        offset += self.num_coefs\n",
    "\n",
    "        self.input_buffer[offset] = midfreq_gain\n",
    "        offset += 1\n",
    "\n",
    "        for coef in range(self.num_coefs):\n",
    "            self.input_buffer[coef + offset] = self.coefs[coef + self.num_coefs] * self.scale_factor\n",
    "        offset += self.num_coefs\n",
    "        \n",
    "        self.input_buffer[offset] = highfreq_gain\n",
    "        offset += 1\n",
    "\n",
    "        for coef in range(self.num_coefs):\n",
    "            self.input_buffer[coef + offset] = self.coefs[coef + 2 * self.num_coefs] * self.scale_factor\n",
    "        offset += self.num_coefs\n",
    "\n",
    "        self.input_buffer[offset] = 0xABBA\n",
    "        offset += 1\n",
    "\n",
    "        for audio_value in range(self.audio_length):\n",
    "            self.input_buffer[audio_value + offset] = self.audio_frames[audio_value]\n",
    "        offset += self.audio_length\n",
    "    \n",
    "    \n",
    "    def run_filter(self, dma):\n",
    "        \"\"\"\n",
    "        run_filter Sends input buffer and receives output buffer from hardware overlay\n",
    "\n",
    "        Args:\n",
    "            dma (overlay ip): AXI Stream DMA IP\n",
    "        \"\"\"\n",
    "        print(0)\n",
    "        dma.sendchannel.transfer(self.input_buffer)\n",
    "        print(1)\n",
    "        dma.recvchannel.transfer(self.output_buffer)\n",
    "        print(2)\n",
    "        dma.sendchannel.wait()\n",
    "        print(3)\n",
    "        dma.recvchannel.wait()\n",
    "        print(4)\n",
    "        \n",
    "    \n",
    "    def write_to_wav_file(self, frames, output_path):\n",
    "        \"\"\"\n",
    "        write_to_wav_file Writes equalized audio signal to output file path\n",
    "\n",
    "        Args:\n",
    "            frames (numpy array): Audio signal frames\n",
    "        \"\"\"\n",
    "        output_frames = np.array(frames).astype(np.int16)\n",
    "        \n",
    "        with wave.open(output_path, 'w') as output_file:\n",
    "            output_file.setnchannels(self.channel_count)\n",
    "            output_file.setsampwidth(self.sample_width)\n",
    "            output_file.setframerate(self.sample_rate)\n",
    "            output_file.writeframes(output_frames)\n",
    "\n",
    "\n",
    "print(\"Created Audio_Signal Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc27e8",
   "metadata": {},
   "source": [
    "#### Audio Signal Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e3e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_input_file_path = './electric_guitar_sample.wav'\n",
    "signal_output_file_path = './outputs/equalized_output.wav'\n",
    "\n",
    "sample_audio = Audio_Signal(signal_input_file_path, signal_output_file_path)\n",
    "\n",
    "sample_audio.load_audio()\n",
    "\n",
    "sample_audio.SW_equalize(0, 1, 0)\n",
    "\n",
    "sample_audio.equalize(0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d2641a",
   "metadata": {},
   "source": [
    "### Results Verification Code\n",
    "Code for printing audio signal values from software and hardware functions for visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Arbitrary value\n",
    "# num_values_to_print = 500\n",
    "\n",
    "# # Prints [num_values_to_print] first and [num_values_to_print] last values from software and hardware\n",
    "# for i in range(num_values_to_print):\n",
    "#     print(\"Software: \", sample_audio.sw_equalized_signal[i], \" Hardware: \", sample_audio.output_buffer[i] / 100000)\n",
    "    \n",
    "# print(\"Switching\")\n",
    "    \n",
    "# for i in range(num_values_to_print):\n",
    "#     print(\"Software: \", sample_audio.sw_equalized_signal[-i], \" Hardware: \", sample_audio.output_buffer[-i - sample_audio.buffer_header_length] / 100000)\n",
    "\n",
    "\n",
    "###   MORE USEFUL TEST FUNCTIONS   ***\n",
    "\n",
    "# Checks every index of the software and hardware results and compares reuslts\n",
    "# Prints index of every location where there is more than a +/-[threshold] difference between the software and hardware results\n",
    "difference_threshold = 2\n",
    "\n",
    "for i in range(len(sample_audio.sw_equalized_signal)):\n",
    "    difference = abs(sample_audio.sw_equalized_signal[i] - (sample_audio.output_buffer[i] / 100000))\n",
    "    if difference > difference_threshold:\n",
    "        print(\"Different at index \", i, \" Difference: \", sample_audio.sw_equalized_signal[i] - (sample_audio.output_buffer[i] / 100000))\n",
    "\n",
    "# Allows for checking arrays at a specific index\n",
    "problem_index = 187700\n",
    "\n",
    "for i in range(500):\n",
    "    print(i , \": Software: \", sample_audio.sw_equalized_signal[i + problem_index], \" Hardware: \", sample_audio.output_buffer[i + problem_index] / 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae52e2",
   "metadata": {},
   "source": [
    "## Guitar Effects Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9a91e0",
   "metadata": {},
   "source": [
    "### Load Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "import numpy as np\n",
    "from pynq import allocate\n",
    "from time import sleep\n",
    "from time import time as timer\n",
    "\n",
    "overlay = Overlay('/home/xilinx/pynq/overlays/final_proj/guitar_effects_design_wrapper.bit')\n",
    "overlay?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecd1730",
   "metadata": {},
   "source": [
    "### Load in Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in audio file\n",
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "\n",
    "file_path = \"./electric_guitar_sample.wav\"\n",
    "\n",
    "with wave.open(file_path, 'r') as wave_file:\n",
    "    # get the number of frames\n",
    "    n_frames = wave_file.getnframes()\n",
    "    # read the frames\n",
    "    full_frames = wave_file.readframes(n_frames)\n",
    "    # convert frames to integers\n",
    "    full_frames = np.frombuffer(full_frames, dtype=np.int16)\n",
    "    \n",
    "    # get the frame rate\n",
    "    frame_rate = wave_file.getframerate()*2 # there are 2 samples per frame, so technically this is sample rate rather than frame rate\n",
    "    # get the time values for the x axis\n",
    "    full_time = np.linspace(0, len(full_frames) / frame_rate, num=len(full_frames))\n",
    "    \n",
    "#only use the first bit of frames so we can save ourselves some time\n",
    "length = 1000000\n",
    "frames = full_frames[:length]\n",
    "time = full_time[:length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022431e",
   "metadata": {},
   "source": [
    "### Define Input and Output Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b29e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(overlay.ip_dict)\n",
    "\n",
    "guitar_effects = overlay.guitar_effects_0\n",
    "dma = overlay.axi_dma_0\n",
    "\n",
    "input = dma.sendchannel\n",
    "output = dma.recvchannel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b010ca2a",
   "metadata": {},
   "source": [
    "### Send Control Inputs through AXI-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all inputs and outputs\n",
    "\n",
    "guitar_effects.register_map.control = 0b1000\n",
    "guitar_effects.register_map.distortion_threshold = 5000\n",
    "guitar_effects.register_map.distortion_clip_factor = 0b001000000 # binary for the value i want\n",
    "guitar_effects.register_map.compression_min_threshold = 1000\n",
    "guitar_effects.register_map.compression_max_threshold = 2000\n",
    "guitar_effects.register_map.zero_threshold = 15\n",
    "guitar_effects.register_map.delay_mult = 0b00111110100000000000000000000000\n",
    "guitar_effects.register_map.delay_samples = 82000\n",
    "guitar_effects.starting_sample = 0\n",
    "# print(guitar_effects.register_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456721b3",
   "metadata": {},
   "source": [
    "### Send data over AXI-Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa76660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay.axi_dma_0?\n",
    "# overlay.ip_dict?\n",
    "start = timer()\n",
    "\n",
    "input_buffer = allocate(shape=(len(frames),), dtype=np.int16)\n",
    "output_buffer = allocate(shape=(len(frames),), dtype=np.int16)\n",
    "input_buffer[:] = frames\n",
    "\n",
    "input.transfer(input_buffer)\n",
    "\n",
    "output.transfer(output_buffer)\n",
    "input.wait()\n",
    "output.wait()\n",
    "\n",
    "\n",
    "end = timer()\n",
    "\n",
    "print(f\"Hardware took {end - start} seconds\")\n",
    "\n",
    "print(type(input_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14809e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot the output waveform THIS WILL TAKE A LONG TIME\n",
    "print(guitar_effects.register_map.axilite_out)\n",
    "print(guitar_effects.register_map.debug_output)\n",
    "print(frames)\n",
    "print(output_buffer)\n",
    "# check if its all zeros so i can save some time\n",
    "all_zeros = True\n",
    "for sample in output_buffer:\n",
    "    if sample != 0:\n",
    "        all_zeros = False\n",
    "        break\n",
    "if all_zeros:\n",
    "    raise ValueError(\"Function returned all zeros!\")\n",
    "\n",
    "plot_length = 1000000\n",
    "plt.figure()\n",
    "plt.legend(loc=1)\n",
    "plt.plot(time[:plot_length], frames[:plot_length], label='Original Waveform')\n",
    "plt.plot(time[:plot_length], output_buffer[:plot_length], label='Processed Waveform')\n",
    "\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Waveform of ' + file_path)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5757454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to a wave file\n",
    "output_sounds = output_buffer.astype(np.int16) # make sure casting is the same\n",
    "# save frames to .wav file\n",
    "wavfile.write('outputs/hardware_result.wav', frame_rate, output_sounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b63deb",
   "metadata": {},
   "source": [
    "# Measuring Speed of PS implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distort(waveform: np.ndarray, threshold: int, clip_factor: float) -> list:\n",
    "    \"\"\"Distort the waveform by clipping the values above the threshold and below the negative threshold and softening the clipped values.\"\"\"\n",
    "    # This function will be replaced by HLS code\n",
    "    distorted_waveform = waveform\n",
    "\n",
    "    # apply clipping\n",
    "    distorted_waveform = np.where(distorted_waveform > threshold, (distorted_waveform - threshold) * clip_factor + threshold, distorted_waveform)\n",
    "    distorted_waveform = np.where(distorted_waveform <  -threshold, (distorted_waveform - threshold) * clip_factor - threshold, distorted_waveform)\n",
    "    # print(type(waveform))\n",
    "    # print(type(distorted_waveform))\n",
    "    distorted_waveform = distorted_waveform.astype(np.int16)\n",
    "    return distorted_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time the distortion algorithm\n",
    "\n",
    "start = timer()\n",
    "\n",
    "threshold = 5000\n",
    "clip_factor = 0.5\n",
    "output = distort(frames, threshold, clip_factor)\n",
    "\n",
    "end = timer()\n",
    "\n",
    "print(f\"PS Distortion took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdded96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amplitude detection used in compression algorithm\n",
    "# THIS USES A FIR LOW PASS FILTER\n",
    "\n",
    "def detect_amplitude(waveform: np.array) -> list:\n",
    "    \"\"\"Returns a np.array of equal lenght corresponding to the amplitude of the waveform at that point.\"\"\"\n",
    "    # This function will be replaced by HLS code\n",
    "    rectified_signal = np.abs(waveform)\n",
    "\n",
    "    # now apply a low pass filter to the rectified signal to envelop detect\n",
    "    filter_length = frame_rate // 200 # frame rate over lowest frequency\n",
    "    filter = np.ones(filter_length) / filter_length # create a filter which will just average the signal over the filter length\n",
    "    filter = filter * 3 # normalize to match amplitude of wave\n",
    "    envelope = np.convolve(rectified_signal, filter, mode='same') # convolve filter with signal\n",
    "    return envelope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f658a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compression algorithm!\n",
    "\n",
    "def compress(waveform: np.array, min_threshold: int, max_threshold: int, zero_threshold: int) -> list:\n",
    "    \"\"\"Compress the waveform by reducing the amplitude of the values above the threshold by the given ratio.\"\"\"\n",
    "    # This function will be replaced by HLS code\n",
    "    envelope = detect_amplitude(waveform)\n",
    "    compressed_waveform = list(waveform)\n",
    "    # if sample is not loud enough, make louder, if too loud make quiter\n",
    "    for i, sample in enumerate(compressed_waveform):\n",
    "        if envelope[i] > max_threshold:\n",
    "            compression_factor = envelope[i] / max_threshold\n",
    "            compressed_waveform[i] = sample / compression_factor\n",
    "        elif envelope[i] < min_threshold and envelope[i] > zero_threshold:\n",
    "            compression_factor = min_threshold / envelope[i]\n",
    "            compressed_waveform[i] = sample * compression_factor\n",
    "    \n",
    "    compressed_waveform = np.array(compressed_waveform, dtype=\"int16\")\n",
    "    return compressed_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae1703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time the compression algorithm\n",
    "\n",
    "start = timer()\n",
    "\n",
    "min_threshold = 2000\n",
    "max_threshold = 3000\n",
    "zero_threshold = 30\n",
    "output = compress(frames, min_threshold, max_threshold, zero_threshold)\n",
    "\n",
    "end = timer()\n",
    "\n",
    "print(f\"PS Compression took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad532f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delay algorithm!!!\n",
    "def delay(waveform: np.array, delay_samples: int, delay_gain: float) -> list:\n",
    "    \"\"\"Adds a delayed version of the waveform to itself with the given delay and gain.\"\"\"\n",
    "    # This function will be replaced by HLS code\n",
    "    delayed_waveform = list(waveform)\n",
    "    for i in range(delay_samples, len(waveform)):\n",
    "        delayed_waveform[i] = delayed_waveform[i] + (delayed_waveform[i - delay_samples] * delay_gain)\n",
    "    # cast as int16\n",
    "    delayed_waveform = np.array(delayed_waveform, dtype=\"int16\")\n",
    "    return delayed_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8449f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time the compression algorithm\n",
    "\n",
    "start = timer()\n",
    "\n",
    "delay_samples = 1500\n",
    "delay_gain = 0.5\n",
    "output = delay(frames, delay_samples, delay_gain)\n",
    "end = timer()\n",
    "\n",
    "print(f\"PS Delay took {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da700b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that takes in an audio waveform and applies a bandpass filter to it\n",
    "def create_filter(lowcut, highcut, order):\n",
    "    nyq_rate = frame_rate / 2.0\n",
    "    low = lowcut / nyq_rate\n",
    "    high = highcut / nyq_rate\n",
    "    taps = np.arange(-order // 2, order // 2 + 1)\n",
    "    filter_kernel = np.sinc(2 * high * taps) - np.sinc(2 * low * taps)\n",
    "    window = np.hamming(order + 1)\n",
    "    filter_kernel *= window\n",
    "    filter_kernel /= np.sum(filter_kernel)\n",
    "    # create window\n",
    "    window = np.hamming(order + 1)\n",
    "    filter_kernel *= window\n",
    "    filter_kernel /= np.sum(filter_kernel)\n",
    "    return filter_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b58867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wah effect\n",
    "# basically a bandpass filter that will change center frequency based on an input signal\n",
    "import math\n",
    "\n",
    "frame_rate = 88200\n",
    "\n",
    "def wah(waveform: np.array, filters, tempo) -> list:\n",
    "    \"\"\"Applies a wah effect to the waveform based on the control signal.\"\"\"\n",
    "    # apply the filter to the waveform\n",
    "    # now basically convolve, but use a different BPF based on the control signal.\n",
    "    wah_waveform = [0] * (len(waveform) + len(filters[0]) - 1)\n",
    "    # iterate though waveform\n",
    "    for i in range(len(waveform)):\n",
    "        print(\"on sample\", i)\n",
    "        control_signal = math.floor(len(filters) * (0.5 + 0.5*(math.sin(0.104*i*tempo/frame_rate))))\n",
    "        #iterate through kernal\n",
    "        for j in range(len(filters[0])): # assuming filters are all the same length\n",
    "            # convolve but only based on the control signal filter\n",
    "            wah_waveform[i + j] += waveform[i] * filters[control_signal][j]\n",
    "    #truncate to length of original waveform\n",
    "    wah_waveform = wah_waveform[:len(waveform)]\n",
    "    #make numpy\n",
    "    wah_waveform = np.array(wah_waveform, dtype=\"int16\")\n",
    "    # Convolve the filter with the data\n",
    "    wah_waveform = wah_waveform.astype(np.int16)\n",
    "    return wah_waveform\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d6126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale # ofvalues to save time\n",
    "samples = 10000\n",
    "\n",
    "# time wah effect \n",
    "min_freq = 200\n",
    "max_freq = 2000\n",
    "filter_count = 10\n",
    "filter_order = 99\n",
    "tempo = 140\n",
    "\n",
    "# do all the stuff that hardware doesnt have to do\n",
    "filters = [create_filter(min_freq + (max_freq - min_freq) * i / filter_count, min_freq + (max_freq - min_freq) * (i + 1) / filter_count, filter_order) for i in range(filter_count)]\n",
    "filters = [filter[::-1] for filter in filters]\n",
    "# change the input signal to an aray of values which will just be the index of the filter to use\n",
    "\n",
    "start = timer()\n",
    "\n",
    "output = wah(frames[:samples], filters, tempo)\n",
    "\n",
    "end = timer()\n",
    "\n",
    "time_mult = len(frames) / samples\n",
    "print(f\"PS Wah took {(end - start)*time_mult} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
